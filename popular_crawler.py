#!/usr/bin/env python3
"""
Bç«™çƒ­é—¨è§†é¢‘é«˜è´¨é‡çˆ¬è™« - çªç ´æ’è¡Œæ¦œé™åˆ¶
Author: GitHub Copilot
Version: 1.0
"""

import requests
import pandas as pd
import time
import random
import sys
import os
from config import *

class BilibiliPopularCrawler:
    def __init__(self):
        """åˆå§‹åŒ–çˆ¬è™«"""
        self.session = requests.Session()
        self.session.headers.update(HEADERS)
        self.data_dir = POPULAR_DIR
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(self.data_dir, exist_ok=True)
        
    def delay(self):
        """éšæœºå»¶è¿Ÿ"""
        delay_time = random.uniform(REQUEST_DELAY_MIN, REQUEST_DELAY_MAX)
        time.sleep(delay_time)
        
    def get_popular_videos(self, target_count=500, max_pages=50):
        """
        è·å–çƒ­é—¨è§†é¢‘æ•°æ®
        
        Args:
            target_count: ç›®æ ‡è§†é¢‘æ•°é‡
            max_pages: æœ€å¤§é¡µæ•°é™åˆ¶
            
        Returns:
            list: è§†é¢‘æ•°æ®åˆ—è¡¨
        """
        all_videos = []
        page = 1
        empty_page_count = 0  # è¿ç»­ç©ºé¡µè®¡æ•°å™¨
        
        print(f"ğŸš€ å¼€å§‹çˆ¬å–çƒ­é—¨è§†é¢‘ï¼Œç›®æ ‡æ•°é‡: {target_count}")
        print(f"âš™ï¸  åœæ­¢æ¡ä»¶: è¿ç»­{MAX_EMPTY_PAGES}é¡µæ— æœ‰æ•ˆæ•°æ®æ—¶åœæ­¢")
        
        while len(all_videos) < target_count and page <= max_pages:
            print(f"ğŸ“„ æ­£åœ¨çˆ¬å–ç¬¬{page}é¡µ...")
            
            url = f"{BASE_URL}{POPULAR_API}"
            params = {
                'ps': 20,  # æ¯é¡µ20ä¸ªè§†é¢‘
                'pn': page
            }
            
            try:
                response = self.session.get(url, params=params, timeout=REQUEST_TIMEOUT)
                
                if response.status_code != 200:
                    print(f"âŒ è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                    empty_page_count += 1
                    if empty_page_count >= MAX_EMPTY_PAGES:
                        print(f"ğŸ“­ è¿ç»­{MAX_EMPTY_PAGES}é¡µè¯·æ±‚å¤±è´¥ï¼Œåœæ­¢çˆ¬å–")
                        break
                    page += 1
                    self.delay()
                    continue
                    
                data = response.json()
                
                if data.get('code') != 0:
                    print(f"âŒ APIé”™è¯¯: {data.get('message')}")
                    empty_page_count += 1
                    if empty_page_count >= MAX_EMPTY_PAGES:
                        print(f"ğŸ“­ è¿ç»­{MAX_EMPTY_PAGES}é¡µAPIé”™è¯¯ï¼Œåœæ­¢çˆ¬å–")
                        break
                    page += 1
                    self.delay()
                    continue
                    
                video_list = data.get('data', {}).get('list', [])
                
                if not video_list:
                    empty_page_count += 1
                    print(f"ğŸ“­ ç¬¬{page}é¡µæ— åŸå§‹æ•°æ®ï¼Œè¿ç»­ç©ºé¡µè®¡æ•°: {empty_page_count}/{MAX_EMPTY_PAGES}")
                    if empty_page_count >= MAX_EMPTY_PAGES:
                        print(f"ğŸ“­ è¿ç»­{MAX_EMPTY_PAGES}é¡µæ— æ•°æ®ï¼Œåœæ­¢çˆ¬å–")
                        break
                    page += 1
                    self.delay()
                    continue
                    
                # å¤„ç†è§†é¢‘æ•°æ®
                page_videos = []
                for video in video_list:
                    processed_video = self.process_video_data(video)
                    if processed_video:
                        page_videos.append(processed_video)
                
                # æ£€æŸ¥æ˜¯å¦è·å–åˆ°æœ‰æ•ˆè§†é¢‘
                if not page_videos:
                    empty_page_count += 1
                    print(f"ğŸ“­ ç¬¬{page}é¡µæ— é«˜è´¨é‡è§†é¢‘ï¼ˆç‚¹èµç‡<{LIKE_RATE_THRESHOLD}ï¼‰ï¼Œè¿ç»­ç©ºé¡µè®¡æ•°: {empty_page_count}/{MAX_EMPTY_PAGES}")
                    if empty_page_count >= MAX_EMPTY_PAGES:
                        print(f"ğŸ“­ è¿ç»­{MAX_EMPTY_PAGES}é¡µæ— æœ‰æ•ˆè§†é¢‘ï¼Œåœæ­¢çˆ¬å–")
                        break
                else:
                    # é‡ç½®è¿ç»­ç©ºé¡µè®¡æ•°å™¨
                    empty_page_count = 0
                
                all_videos.extend(page_videos)
                
                print(f"âœ… ç¬¬{page}é¡µè·å– {len(page_videos)} ä¸ªè§†é¢‘ï¼Œæ€»è®¡: {len(all_videos)}")
                
                page += 1
                self.delay()
                
            except Exception as e:
                print(f"âŒ çˆ¬å–ç¬¬{page}é¡µæ—¶å‡ºé”™: {e}")
                empty_page_count += 1
                if empty_page_count >= MAX_EMPTY_PAGES:
                    print(f"ğŸ“­ è¿ç»­{MAX_EMPTY_PAGES}é¡µå‡ºé”™ï¼Œåœæ­¢çˆ¬å–")
                    break
                page += 1
                self.delay()
        
        print(f"ğŸ‰ çˆ¬å–å®Œæˆï¼å…±è·å– {len(all_videos)} ä¸ªè§†é¢‘")
        return all_videos
    
    def process_video_data(self, video):
        """
        å¤„ç†å•ä¸ªè§†é¢‘æ•°æ®
        
        Args:
            video: åŸå§‹è§†é¢‘æ•°æ®
            
        Returns:
            dict: å¤„ç†åçš„è§†é¢‘æ•°æ®
        """
        try:
            # åŸºç¡€ä¿¡æ¯
            bvid = video.get('bvid', '')
            title = video.get('title', '').strip()
            
            # ä½œè€…ä¿¡æ¯
            owner = video.get('owner', {})
            author = owner.get('name', '')
            
            # ç»Ÿè®¡æ•°æ®
            stat = video.get('stat', {})
            view = stat.get('view', 0)
            like = stat.get('like', 0)
            coin = stat.get('coin', 0)
            favorite = stat.get('favorite', 0)
            share = stat.get('share', 0)
            reply = stat.get('reply', 0)
            danmaku = stat.get('danmaku', 0)
            
            # å…¶ä»–ä¿¡æ¯
            duration = video.get('duration', 0)
            pubdate = video.get('pubdate', 0)
            pic = video.get('pic', '')
            desc = video.get('desc', '').strip()
            
            # è®¡ç®—ç‚¹èµç‡
            like_rate = like / view if view > 0 else 0
            
            # åªä¿ç•™é«˜è´¨é‡è§†é¢‘
            if like_rate < LIKE_RATE_THRESHOLD:
                return None
            
            return {
                'bvid': bvid,
                'title': title,
                'author': author,
                'view': view,
                'like': like,
                'coin': coin,
                'favorite': favorite,
                'share': share,
                'reply': reply,
                'danmaku': danmaku,
                'like_rate': round(like_rate, 4),
                'duration': duration,
                'pubdate': pubdate,
                'pic': pic,
                'desc': desc[:200],  # é™åˆ¶æè¿°é•¿åº¦
                'url': f'https://www.bilibili.com/video/{bvid}'
            }
            
        except Exception as e:
            print(f"âŒ å¤„ç†è§†é¢‘æ•°æ®æ—¶å‡ºé”™: {e}")
            return None
    
    def save_to_csv(self, videos, filename):
        """
        ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶
        
        Args:
            videos: è§†é¢‘æ•°æ®åˆ—è¡¨
            filename: æ–‡ä»¶å
        """
        if not videos:
            print("âŒ æ— æ•°æ®å¯ä¿å­˜")
            return
            
        df = pd.DataFrame(videos)
        
        # æŒ‰ç‚¹èµç‡æ’åº
        df = df.sort_values('like_rate', ascending=False)
        
        # æ·»åŠ æ’å
        df['rank'] = range(1, len(df) + 1)
        
        # é‡æ–°æ’åˆ—åˆ—é¡ºåº
        columns = ['rank', 'title', 'author', 'view', 'like', 'like_rate', 
                  'coin', 'favorite', 'share', 'reply', 'danmaku', 
                  'duration', 'url', 'bvid', 'desc']
        df = df[columns]
        
        # ä¿å­˜æ–‡ä»¶
        filepath = os.path.join(self.data_dir, filename)
        df.to_csv(filepath, index=False, encoding='utf-8-sig')
        
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
        print(f"ğŸ“Š å…±ä¿å­˜ {len(df)} ä¸ªé«˜è´¨é‡è§†é¢‘")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print(f"\nğŸ“ˆ è´¨é‡ç»Ÿè®¡:")
        print(f"å¹³å‡ç‚¹èµç‡: {df['like_rate'].mean():.4f}")
        print(f"æœ€é«˜ç‚¹èµç‡: {df['like_rate'].max():.4f}")
        print(f"å¹³å‡æ’­æ”¾é‡: {df['view'].mean():,.0f}")
        print(f"å¹³å‡ç‚¹èµæ•°: {df['like'].mean():,.0f}")
    
    def run(self, target_count=None):
        """
        è¿è¡Œçˆ¬è™«
        
        Args:
            target_count: ç›®æ ‡è§†é¢‘æ•°é‡ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®æ–‡ä»¶å€¼
        """
        if target_count is None:
            target_count = TARGET_COUNT_POPULAR
            
        print(f"ğŸ¯ å¼€å§‹çˆ¬å–Bç«™çƒ­é—¨é«˜è´¨é‡è§†é¢‘...")
        print(f"âš™ï¸  é…ç½®: ç‚¹èµç‡é˜ˆå€¼ {LIKE_RATE_THRESHOLD}, ç›®æ ‡æ•°é‡ {target_count}")
        
        # è·å–è§†é¢‘æ•°æ®
        videos = self.get_popular_videos(target_count)
        
        if videos:
            # ä¿å­˜æ•°æ®
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"Bç«™çƒ­é—¨-é«˜è´¨é‡-{timestamp}.csv"
            self.save_to_csv(videos, filename)
        else:
            print("âŒ æœªè·å–åˆ°ä»»ä½•è§†é¢‘æ•°æ®")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¥ Bç«™çƒ­é—¨è§†é¢‘é«˜è´¨é‡çˆ¬è™« v1.0")
    print("=" * 50)
    
    try:
        crawler = BilibiliPopularCrawler()
        
        # å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œå‚æ•°æŒ‡å®šç›®æ ‡æ•°é‡
        target_count = None
        if len(sys.argv) > 1:
            try:
                target_count = int(sys.argv[1])
                print(f"ğŸ“‹ ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼Œç›®æ ‡æ•°é‡: {target_count}")
            except ValueError:
                print(f"âŒ æ— æ•ˆçš„æ•°é‡å‚æ•°: {sys.argv[1]}")
                sys.exit(1)
        
        crawler.run(target_count)
        print("\nğŸ‰ çˆ¬å–ä»»åŠ¡å®Œæˆï¼")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­çˆ¬å–")
    except Exception as e:
        print(f"\nâŒ çˆ¬å–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
